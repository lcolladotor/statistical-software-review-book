<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Scope | rOpenSci Statistical Software Peer Review</title>
  <meta name="description" content="Chapter 4 Scope | rOpenSci Statistical Software Peer Review" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Scope | rOpenSci Statistical Software Peer Review" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://ropensci-blog-guidance.netlify.com/" />
  
  
  <meta name="github-repo" content="ropenscilabs/statistical-software-review-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Scope | rOpenSci Statistical Software Peer Review" />
  
  
  

<meta name="author" content="Mark Padgham and Noam Ross" />


<meta name="date" content="2020-10-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="favicon/apple-touch-icon.png" />
  <link rel="shortcut icon" href="favicon/favicon.ico" type="image/x-icon" />
<link rel="prev" href="reading.html"/>
<link rel="next" href="standards.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/htmlwidgets-1.5.2/htmlwidgets.js"></script>
<link href="libs/vis-4.20.1/vis.css" rel="stylesheet" />
<script src="libs/vis-4.20.1/vis.min.js"></script>
<script src="libs/visNetwork-binding-2.0.9/visNetwork.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://github.com/ropenscilabs/statistical-software-review-book"><i class="fa fa-github"></i> Statistical Software Peer Review</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Welcome</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#contributors"><i class="fa fa-check"></i><b>1.1</b> Contributors</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#content"><i class="fa fa-check"></i><b>1.2</b> Content</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#issue-authors"><i class="fa fa-check"></i><b>1.3</b> Issue Authors</a></li>
</ul></li>
<li class="part"><span><b>I Introduction</b></span></li>
<li class="chapter" data-level="2" data-path="overview.html"><a href="overview.html"><i class="fa fa-check"></i><b>2</b> Project Overview</a><ul>
<li class="chapter" data-level="2.1" data-path="overview.html"><a href="overview.html#project-aims"><i class="fa fa-check"></i><b>2.1</b> Project Aims</a></li>
<li class="chapter" data-level="2.2" data-path="overview.html"><a href="overview.html#related-projects-and-initiatives"><i class="fa fa-check"></i><b>2.2</b> Related projects and initiatives</a></li>
<li class="chapter" data-level="2.3" data-path="overview.html"><a href="overview.html#outline-of-this-document"><i class="fa fa-check"></i><b>2.3</b> Outline of this document</a><ul>
<li class="chapter" data-level="2.3.1" data-path="overview.html"><a href="overview.html#scope-of-statistical-software-review"><i class="fa fa-check"></i><b>2.3.1</b> Scope of Statistical Software Review</a></li>
<li class="chapter" data-level="2.3.2" data-path="overview.html"><a href="overview.html#standards-for-statistical-software"><i class="fa fa-check"></i><b>2.3.2</b> Standards for Statistical Software</a></li>
<li class="chapter" data-level="2.3.3" data-path="overview.html"><a href="overview.html#software-assessment"><i class="fa fa-check"></i><b>2.3.3</b> Software Assessment</a></li>
<li class="chapter" data-level="2.3.4" data-path="overview.html"><a href="overview.html#statistical-software-peer-review-process"><i class="fa fa-check"></i><b>2.3.4</b> Statistical Software Peer Review Process</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="overview.html"><a href="overview.html#community"><i class="fa fa-check"></i><b>2.4</b> Community</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="reading.html"><a href="reading.html"><i class="fa fa-check"></i><b>3</b> Some Light Reading: An Annotated Bibliography</a><ul>
<li class="chapter" data-level="3.1" data-path="reading.html"><a href="reading.html#books"><i class="fa fa-check"></i><b>3.1</b> Books</a></li>
<li class="chapter" data-level="3.2" data-path="reading.html"><a href="reading.html#journal-articles"><i class="fa fa-check"></i><b>3.2</b> Journal Articles</a></li>
<li class="chapter" data-level="3.3" data-path="reading.html"><a href="reading.html#technical-reports"><i class="fa fa-check"></i><b>3.3</b> Technical Reports</a></li>
<li class="chapter" data-level="3.4" data-path="reading.html"><a href="reading.html#computer-programs"><i class="fa fa-check"></i><b>3.4</b> Computer Programs</a><ul>
<li class="chapter" data-level="3.4.1" data-path="reading.html"><a href="reading.html#computer-programs-testing"><i class="fa fa-check"></i><b>3.4.1</b> Computer Programs (Testing)</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="reading.html"><a href="reading.html#web-pages"><i class="fa fa-check"></i><b>3.5</b> Web Pages</a></li>
<li class="chapter" data-level="3.6" data-path="reading.html"><a href="reading.html#contributing-to-the-biblopgraphy"><i class="fa fa-check"></i><b>3.6</b> Contributing to the bibliography</a></li>
</ul></li>
<li class="part"><span><b>II Scope and Standards</b></span></li>
<li class="chapter" data-level="4" data-path="scope.html"><a href="scope.html"><i class="fa fa-check"></i><b>4</b> Scope</a><ul>
<li class="chapter" data-level="4.1" data-path="scope.html"><a href="scope.html#software-types"><i class="fa fa-check"></i><b>4.1</b> Software types</a><ul>
<li class="chapter" data-level="4.1.1" data-path="scope.html"><a href="scope.html#languages"><i class="fa fa-check"></i><b>4.1.1</b> Languages</a></li>
<li class="chapter" data-level="4.1.2" data-path="scope.html"><a href="scope.html#structure"><i class="fa fa-check"></i><b>4.1.2</b> Structure</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="scope.html"><a href="scope.html#scope-categories-bg"><i class="fa fa-check"></i><b>4.2</b> Statistical Categories – Background</a><ul>
<li class="chapter" data-level="4.2.1" data-path="scope.html"><a href="scope.html#empirical-derivation-of-categories"><i class="fa fa-check"></i><b>4.2.1</b> Empirical Derivation of Categories</a></li>
<li class="chapter" data-level="4.2.2" data-path="scope.html"><a href="scope.html#examples-of-statistical-software"><i class="fa fa-check"></i><b>4.2.2</b> Examples of Statistical Software</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="scope.html"><a href="scope.html#scope-categories"><i class="fa fa-check"></i><b>4.3</b> Statistical Categories</a><ul>
<li class="chapter" data-level="4.3.1" data-path="scope.html"><a href="scope.html#scope-category-bayesian"><i class="fa fa-check"></i><b>4.3.1</b> Bayesian and Monte Carlo Routines</a></li>
<li class="chapter" data-level="4.3.2" data-path="scope.html"><a href="scope.html#scope-category-unsupervised"><i class="fa fa-check"></i><b>4.3.2</b> Dimensionality Reduction, Clustering, and Unsupervised Learning</a></li>
<li class="chapter" data-level="4.3.3" data-path="scope.html"><a href="scope.html#scope-category-ML"><i class="fa fa-check"></i><b>4.3.3</b> Machine Learning</a></li>
<li class="chapter" data-level="4.3.4" data-path="scope.html"><a href="scope.html#scope-category-supervised"><i class="fa fa-check"></i><b>4.3.4</b> Regression and Supervised Learning</a></li>
<li class="chapter" data-level="4.3.5" data-path="scope.html"><a href="scope.html#scope-category-distributions"><i class="fa fa-check"></i><b>4.3.5</b> Probability Distributions</a></li>
<li class="chapter" data-level="4.3.6" data-path="scope.html"><a href="scope.html#scope-category-wrapper"><i class="fa fa-check"></i><b>4.3.6</b> Wrapper Packages</a></li>
<li class="chapter" data-level="4.3.7" data-path="scope.html"><a href="scope.html#scope-category-networks"><i class="fa fa-check"></i><b>4.3.7</b> Networks</a></li>
<li class="chapter" data-level="4.3.8" data-path="scope.html"><a href="scope.html#scope-category-EDA"><i class="fa fa-check"></i><b>4.3.8</b> Exploratory Data Analysis (EDA) and Summary Statistics</a></li>
<li class="chapter" data-level="4.3.9" data-path="scope.html"><a href="scope.html#scope-category-workflow"><i class="fa fa-check"></i><b>4.3.9</b> Workflow Support</a></li>
<li class="chapter" data-level="4.3.10" data-path="scope.html"><a href="scope.html#scope-category-spatial"><i class="fa fa-check"></i><b>4.3.10</b> Spatial Analyses</a></li>
<li class="chapter" data-level="4.3.11" data-path="scope.html"><a href="scope.html#scope-category-time"><i class="fa fa-check"></i><b>4.3.11</b> Time Series Analyses</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="scope.html"><a href="scope.html#out-of-scope-categories"><i class="fa fa-check"></i><b>4.4</b> Out Of Scope Categories</a><ul>
<li class="chapter" data-level="4.4.1" data-path="scope.html"><a href="scope.html#visualisation"><i class="fa fa-check"></i><b>4.4.1</b> Visualisation</a></li>
<li class="chapter" data-level="4.4.2" data-path="scope.html"><a href="scope.html#education"><i class="fa fa-check"></i><b>4.4.2</b> Education</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="scope.html"><a href="scope.html#proposals"><i class="fa fa-check"></i><b>4.5</b> Proposals</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="standards.html"><a href="standards.html"><i class="fa fa-check"></i><b>5</b> <span style="color:red;">Standards [SEEKING FEEDBACK]<span></a><ul>
<li class="chapter" data-level="5.1" data-path="standards.html"><a href="standards.html#other-standards"><i class="fa fa-check"></i><b>5.1</b> Other Standards</a></li>
<li class="chapter" data-level="5.2" data-path="standards.html"><a href="standards.html#general-standards-for-statistical-software"><i class="fa fa-check"></i><b>5.2</b> General Standards for Statistical Software</a><ul>
<li class="chapter" data-level="5.2.1" data-path="standards.html"><a href="standards.html#documentation"><i class="fa fa-check"></i><b>5.2.1</b> Documentation</a></li>
<li class="chapter" data-level="5.2.2" data-path="standards.html"><a href="standards.html#input-structures"><i class="fa fa-check"></i><b>5.2.2</b> Input Structures</a><ul>
<li class="chapter" data-level="5.2.2.1" data-path="standards.html"><a href="standards.html#uni-variate-vector-input"><i class="fa fa-check"></i><b>5.2.2.1</b> Uni-variate (Vector) Input</a></li>
<li class="chapter" data-level="5.2.2.2" data-path="standards.html"><a href="standards.html#tabular-input"><i class="fa fa-check"></i><b>5.2.2.2</b> Tabular Input</a></li>
<li class="chapter" data-level="5.2.2.3" data-path="standards.html"><a href="standards.html#missing-or-undefined-values"><i class="fa fa-check"></i><b>5.2.2.3</b> Missing or Undefined Values</a></li>
</ul></li>
<li class="chapter" data-level="5.2.3" data-path="standards.html"><a href="standards.html#output-structures"><i class="fa fa-check"></i><b>5.2.3</b> Output Structures</a></li>
<li class="chapter" data-level="5.2.4" data-path="standards.html"><a href="standards.html#testing"><i class="fa fa-check"></i><b>5.2.4</b> Testing</a><ul>
<li class="chapter" data-level="5.2.4.1" data-path="standards.html"><a href="standards.html#extended-tests"><i class="fa fa-check"></i><b>5.2.4.1</b> Extended tests</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="standards.html"><a href="standards.html#bayesian-and-monte-carlo-software"><i class="fa fa-check"></i><b>5.3</b> Bayesian and Monte Carlo Software</a><ul>
<li class="chapter" data-level="5.3.1" data-path="standards.html"><a href="standards.html#documentation-of-inputs"><i class="fa fa-check"></i><b>5.3.1</b> Documentation of Inputs</a></li>
<li class="chapter" data-level="5.3.2" data-path="standards.html"><a href="standards.html#input-data-structures-and-validation"><i class="fa fa-check"></i><b>5.3.2</b> Input Data Structures and Validation</a><ul>
<li class="chapter" data-level="5.3.2.1" data-path="standards.html"><a href="standards.html#input-data"><i class="fa fa-check"></i><b>5.3.2.1</b> Input Data</a></li>
<li class="chapter" data-level="5.3.2.2" data-path="standards.html"><a href="standards.html#prior-distributions-model-specifications-and-hyperparameters"><i class="fa fa-check"></i><b>5.3.2.2</b> Prior Distributions, Model Specifications, and Hyperparameters</a></li>
<li class="chapter" data-level="5.3.2.3" data-path="standards.html"><a href="standards.html#computational-parameters"><i class="fa fa-check"></i><b>5.3.2.3</b> Computational Parameters</a></li>
<li class="chapter" data-level="5.3.2.4" data-path="standards.html"><a href="standards.html#seed-parameters"><i class="fa fa-check"></i><b>5.3.2.4</b> Seed Parameters</a></li>
<li class="chapter" data-level="5.3.2.5" data-path="standards.html"><a href="standards.html#output-verbosity"><i class="fa fa-check"></i><b>5.3.2.5</b> Output Verbosity</a></li>
</ul></li>
<li class="chapter" data-level="5.3.3" data-path="standards.html"><a href="standards.html#pre-processing-and-data-transformation"><i class="fa fa-check"></i><b>5.3.3</b> Pre-processing and Data Transformation</a><ul>
<li class="chapter" data-level="5.3.3.1" data-path="standards.html"><a href="standards.html#missing-values"><i class="fa fa-check"></i><b>5.3.3.1</b> Missing Values</a></li>
<li class="chapter" data-level="5.3.3.2" data-path="standards.html"><a href="standards.html#perfect-collinearity"><i class="fa fa-check"></i><b>5.3.3.2</b> Perfect Collinearity</a></li>
</ul></li>
<li class="chapter" data-level="5.3.4" data-path="standards.html"><a href="standards.html#analytic-algorithms"><i class="fa fa-check"></i><b>5.3.4</b> Analytic Algorithms</a></li>
<li class="chapter" data-level="5.3.5" data-path="standards.html"><a href="standards.html#return-values"><i class="fa fa-check"></i><b>5.3.5</b> Return Values</a></li>
<li class="chapter" data-level="5.3.6" data-path="standards.html"><a href="standards.html#additional-functionality"><i class="fa fa-check"></i><b>5.3.6</b> Additional Functionality</a></li>
<li class="chapter" data-level="5.3.7" data-path="standards.html"><a href="standards.html#tests"><i class="fa fa-check"></i><b>5.3.7</b> Tests</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="standards.html"><a href="standards.html#regression-and-supervised-learning"><i class="fa fa-check"></i><b>5.4</b> Regression and Supervised Learning</a><ul>
<li class="chapter" data-level="5.4.1" data-path="standards.html"><a href="standards.html#input-data-structures-and-validation-1"><i class="fa fa-check"></i><b>5.4.1</b> Input data structures and validation</a></li>
<li class="chapter" data-level="5.4.2" data-path="standards.html"><a href="standards.html#pre-processing-and-variable-transformation"><i class="fa fa-check"></i><b>5.4.2</b> Pre-processing and Variable Transformation</a></li>
<li class="chapter" data-level="5.4.3" data-path="standards.html"><a href="standards.html#algorithms"><i class="fa fa-check"></i><b>5.4.3</b> Algorithms</a></li>
<li class="chapter" data-level="5.4.4" data-path="standards.html"><a href="standards.html#return-results"><i class="fa fa-check"></i><b>5.4.4</b> Return Results</a><ul>
<li class="chapter" data-level="5.4.4.1" data-path="standards.html"><a href="standards.html#accessor-methods"><i class="fa fa-check"></i><b>5.4.4.1</b> Accessor Methods</a></li>
<li class="chapter" data-level="5.4.4.2" data-path="standards.html"><a href="standards.html#prediction-extrapolation-and-forecasting"><i class="fa fa-check"></i><b>5.4.4.2</b> Prediction, Extrapolation, and Forecasting</a></li>
<li class="chapter" data-level="5.4.4.3" data-path="standards.html"><a href="standards.html#reporting-return-results"><i class="fa fa-check"></i><b>5.4.4.3</b> Reporting Return Results</a></li>
</ul></li>
<li class="chapter" data-level="5.4.5" data-path="standards.html"><a href="standards.html#documentation-1"><i class="fa fa-check"></i><b>5.4.5</b> Documentation</a></li>
<li class="chapter" data-level="5.4.6" data-path="standards.html"><a href="standards.html#visualization"><i class="fa fa-check"></i><b>5.4.6</b> Visualization</a></li>
<li class="chapter" data-level="5.4.7" data-path="standards.html"><a href="standards.html#testing-1"><i class="fa fa-check"></i><b>5.4.7</b> Testing</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="standards.html"><a href="standards.html#dimensionality-reduction-clustering-and-unsupervised-learning"><i class="fa fa-check"></i><b>5.5</b> Dimensionality Reduction, Clustering, and Unsupervised Learning</a><ul>
<li class="chapter" data-level="5.5.1" data-path="standards.html"><a href="standards.html#input-data-structures-and-validation-2"><i class="fa fa-check"></i><b>5.5.1</b> Input Data Structures and Validation</a></li>
<li class="chapter" data-level="5.5.2" data-path="standards.html"><a href="standards.html#pre-processing-and-variable-transformation-1"><i class="fa fa-check"></i><b>5.5.2</b> Pre-processing and Variable Transformation</a></li>
<li class="chapter" data-level="5.5.3" data-path="standards.html"><a href="standards.html#algorithms-1"><i class="fa fa-check"></i><b>5.5.3</b> Algorithms</a><ul>
<li class="chapter" data-level="5.5.3.1" data-path="standards.html"><a href="standards.html#labelling"><i class="fa fa-check"></i><b>5.5.3.1</b> Labelling</a></li>
<li class="chapter" data-level="5.5.3.2" data-path="standards.html"><a href="standards.html#prediction"><i class="fa fa-check"></i><b>5.5.3.2</b> Prediction</a></li>
<li class="chapter" data-level="5.5.3.3" data-path="standards.html"><a href="standards.html#group-distributions-and-associated-statistics"><i class="fa fa-check"></i><b>5.5.3.3</b> Group Distributions and Associated Statistics</a></li>
</ul></li>
<li class="chapter" data-level="5.5.4" data-path="standards.html"><a href="standards.html#return-results-1"><i class="fa fa-check"></i><b>5.5.4</b> Return Results</a><ul>
<li class="chapter" data-level="5.5.4.1" data-path="standards.html"><a href="standards.html#reporting-return-results-1"><i class="fa fa-check"></i><b>5.5.4.1</b> Reporting Return Results</a></li>
</ul></li>
<li class="chapter" data-level="5.5.5" data-path="standards.html"><a href="standards.html#documentation-2"><i class="fa fa-check"></i><b>5.5.5</b> Documentation</a></li>
<li class="chapter" data-level="5.5.6" data-path="standards.html"><a href="standards.html#visualization-1"><i class="fa fa-check"></i><b>5.5.6</b> Visualization</a></li>
<li class="chapter" data-level="5.5.7" data-path="standards.html"><a href="standards.html#testing-2"><i class="fa fa-check"></i><b>5.5.7</b> Testing</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="standards.html"><a href="standards.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>5.6</b> Exploratory Data Analysis</a><ul>
<li class="chapter" data-level="5.6.1" data-path="standards.html"><a href="standards.html#documentation-standards"><i class="fa fa-check"></i><b>5.6.1</b> Documentation Standards</a></li>
<li class="chapter" data-level="5.6.2" data-path="standards.html"><a href="standards.html#input-data-1"><i class="fa fa-check"></i><b>5.6.2</b> Input Data</a><ul>
<li class="chapter" data-level="5.6.2.1" data-path="standards.html"><a href="standards.html#index-columns"><i class="fa fa-check"></i><b>5.6.2.1</b> Index Columns</a></li>
<li class="chapter" data-level="5.6.2.2" data-path="standards.html"><a href="standards.html#multi-tabular-input"><i class="fa fa-check"></i><b>5.6.2.2</b> Multi-tabular input</a></li>
<li class="chapter" data-level="5.6.2.3" data-path="standards.html"><a href="standards.html#classes-and-sub-classes"><i class="fa fa-check"></i><b>5.6.2.3</b> Classes and Sub-Classes</a></li>
</ul></li>
<li class="chapter" data-level="5.6.3" data-path="standards.html"><a href="standards.html#analytic-algorithms-1"><i class="fa fa-check"></i><b>5.6.3</b> Analytic Algorithms</a></li>
<li class="chapter" data-level="5.6.4" data-path="standards.html"><a href="standards.html#return-results-output-data"><i class="fa fa-check"></i><b>5.6.4</b> Return Results / Output Data</a></li>
<li class="chapter" data-level="5.6.5" data-path="standards.html"><a href="standards.html#visualization-and-summary-output"><i class="fa fa-check"></i><b>5.6.5</b> Visualization and Summary Output</a><ul>
<li class="chapter" data-level="5.6.5.1" data-path="standards.html"><a href="standards.html#summary-and-screen-based-output"><i class="fa fa-check"></i><b>5.6.5.1</b> Summary and Screen-based Output</a></li>
<li class="chapter" data-level="5.6.5.2" data-path="standards.html"><a href="standards.html#general-standards-for-visualization-static-and-dynamic"><i class="fa fa-check"></i><b>5.6.5.2</b> General Standards for Visualization (Static and Dynamic)</a></li>
<li class="chapter" data-level="5.6.5.3" data-path="standards.html"><a href="standards.html#dynamic-visualization"><i class="fa fa-check"></i><b>5.6.5.3</b> Dynamic Visualization</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="standards.html"><a href="standards.html#time-series-software"><i class="fa fa-check"></i><b>5.7</b> Time Series Software</a><ul>
<li class="chapter" data-level="5.7.1" data-path="standards.html"><a href="standards.html#input-data-structures-and-validation-3"><i class="fa fa-check"></i><b>5.7.1</b> Input data structures and validation</a><ul>
<li class="chapter" data-level="5.7.1.1" data-path="standards.html"><a href="standards.html#time-intervals-and-relative-time"><i class="fa fa-check"></i><b>5.7.1.1</b> Time Intervals and Relative Time</a></li>
</ul></li>
<li class="chapter" data-level="5.7.2" data-path="standards.html"><a href="standards.html#pre-processing-and-variable-transformation-2"><i class="fa fa-check"></i><b>5.7.2</b> Pre-processing and Variable Transformation</a><ul>
<li class="chapter" data-level="5.7.2.1" data-path="standards.html"><a href="standards.html#missing-data"><i class="fa fa-check"></i><b>5.7.2.1</b> Missing Data</a></li>
<li class="chapter" data-level="5.7.2.2" data-path="standards.html"><a href="standards.html#stationarity"><i class="fa fa-check"></i><b>5.7.2.2</b> Stationarity</a></li>
<li class="chapter" data-level="5.7.2.3" data-path="standards.html"><a href="standards.html#covariance-matrices"><i class="fa fa-check"></i><b>5.7.2.3</b> Covariance Matrices</a></li>
</ul></li>
<li class="chapter" data-level="5.7.3" data-path="standards.html"><a href="standards.html#analytic-algorithms-2"><i class="fa fa-check"></i><b>5.7.3</b> Analytic Algorithms</a><ul>
<li class="chapter" data-level="5.7.3.1" data-path="standards.html"><a href="standards.html#forecasting"><i class="fa fa-check"></i><b>5.7.3.1</b> Forecasting</a></li>
</ul></li>
<li class="chapter" data-level="5.7.4" data-path="standards.html"><a href="standards.html#return-results-2"><i class="fa fa-check"></i><b>5.7.4</b> Return Results</a><ul>
<li class="chapter" data-level="5.7.4.1" data-path="standards.html"><a href="standards.html#data-transformation"><i class="fa fa-check"></i><b>5.7.4.1</b> Data Transformation</a></li>
<li class="chapter" data-level="5.7.4.2" data-path="standards.html"><a href="standards.html#forecasting-1"><i class="fa fa-check"></i><b>5.7.4.2</b> Forecasting</a></li>
</ul></li>
<li class="chapter" data-level="5.7.5" data-path="standards.html"><a href="standards.html#visualization-2"><i class="fa fa-check"></i><b>5.7.5</b> Visualization</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="standards.html"><a href="standards.html#machine-learning-software"><i class="fa fa-check"></i><b>5.8</b> Machine Learning Software</a><ul>
<li class="chapter" data-level="5.8.1" data-path="standards.html"><a href="standards.html#input-data-specification"><i class="fa fa-check"></i><b>5.8.1</b> Input Data Specification</a><ul>
<li class="chapter" data-level="5.8.1.1" data-path="standards.html"><a href="standards.html#missing-values-1"><i class="fa fa-check"></i><b>5.8.1.1</b> Missing Values</a></li>
</ul></li>
<li class="chapter" data-level="5.8.2" data-path="standards.html"><a href="standards.html#pre-processing"><i class="fa fa-check"></i><b>5.8.2</b> Pre-processing</a></li>
<li class="chapter" data-level="5.8.3" data-path="standards.html"><a href="standards.html#model-and-algorithm-specification"><i class="fa fa-check"></i><b>5.8.3</b> Model and Algorithm Specification</a><ul>
<li class="chapter" data-level="5.8.3.1" data-path="standards.html"><a href="standards.html#control-parameters"><i class="fa fa-check"></i><b>5.8.3.1</b> Control Parameters</a></li>
<li class="chapter" data-level="5.8.3.2" data-path="standards.html"><a href="standards.html#cpu-and-gpu-processing"><i class="fa fa-check"></i><b>5.8.3.2</b> CPU and GPU processing</a></li>
</ul></li>
<li class="chapter" data-level="5.8.4" data-path="standards.html"><a href="standards.html#model-training"><i class="fa fa-check"></i><b>5.8.4</b> Model Training</a><ul>
<li class="chapter" data-level="5.8.4.1" data-path="standards.html"><a href="standards.html#batch-processing"><i class="fa fa-check"></i><b>5.8.4.1</b> Batch Processing</a></li>
<li class="chapter" data-level="5.8.4.2" data-path="standards.html"><a href="standards.html#re-sampling"><i class="fa fa-check"></i><b>5.8.4.2</b> Re-sampling</a></li>
</ul></li>
<li class="chapter" data-level="5.8.5" data-path="standards.html"><a href="standards.html#model-output-and-performance"><i class="fa fa-check"></i><b>5.8.5</b> Model Output and Performance</a><ul>
<li class="chapter" data-level="5.8.5.1" data-path="standards.html"><a href="standards.html#model-output"><i class="fa fa-check"></i><b>5.8.5.1</b> Model Output</a></li>
<li class="chapter" data-level="5.8.5.2" data-path="standards.html"><a href="standards.html#model-performance"><i class="fa fa-check"></i><b>5.8.5.2</b> Model Performance</a></li>
</ul></li>
<li class="chapter" data-level="5.8.6" data-path="standards.html"><a href="standards.html#documentation-3"><i class="fa fa-check"></i><b>5.8.6</b> Documentation</a></li>
<li class="chapter" data-level="5.8.7" data-path="standards.html"><a href="standards.html#testing-3"><i class="fa fa-check"></i><b>5.8.7</b> Testing</a><ul>
<li class="chapter" data-level="5.8.7.1" data-path="standards.html"><a href="standards.html#input-data-2"><i class="fa fa-check"></i><b>5.8.7.1</b> Input Data</a></li>
<li class="chapter" data-level="5.8.7.2" data-path="standards.html"><a href="standards.html#model-classes"><i class="fa fa-check"></i><b>5.8.7.2</b> Model Classes</a></li>
<li class="chapter" data-level="5.8.7.3" data-path="standards.html"><a href="standards.html#model-training-1"><i class="fa fa-check"></i><b>5.8.7.3</b> Model Training</a></li>
<li class="chapter" data-level="5.8.7.4" data-path="standards.html"><a href="standards.html#model-performance-1"><i class="fa fa-check"></i><b>5.8.7.4</b> Model Performance</a></li>
</ul></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="assessment.html"><a href="assessment.html"><i class="fa fa-check"></i><b>6</b> Assessment</a><ul>
<li class="chapter" data-level="6.1" data-path="assessment.html"><a href="assessment.html#general-software-metrics"><i class="fa fa-check"></i><b>6.1</b> General Software Metrics</a></li>
<li class="chapter" data-level="6.2" data-path="assessment.html"><a href="assessment.html#metrics-specific-to-statistical-software"><i class="fa fa-check"></i><b>6.2</b> Metrics specific to statistical software</a></li>
<li class="chapter" data-level="6.3" data-path="assessment.html"><a href="assessment.html#diagnostics-and-reporting"><i class="fa fa-check"></i><b>6.3</b> Diagnostics and Reporting</a></li>
<li class="chapter" data-level="6.4" data-path="assessment.html"><a href="assessment.html#proposals-and-aims"><i class="fa fa-check"></i><b>6.4</b> Proposals and Aims</a></li>
</ul></li>
<li class="part"><span><b>III Software Review Process and Software Assessment</b></span></li>
<li class="chapter" data-level="7" data-path="lifeycle.html"><a href="lifeycle.html"><i class="fa fa-check"></i><b>7</b> <span style="color:red;">Software Review and Life Cycle Models [Seeking Feedback]</span></a><ul>
<li class="chapter" data-level="7.1" data-path="lifeycle.html"><a href="lifeycle.html#other-systems-for-software-and-peer-review"><i class="fa fa-check"></i><b>7.1</b> Other systems for software and peer review</a><ul>
<li class="chapter" data-level="7.1.1" data-path="lifeycle.html"><a href="lifeycle.html#ropensci"><i class="fa fa-check"></i><b>7.1.1</b> rOpenSci</a></li>
<li class="chapter" data-level="7.1.2" data-path="lifeycle.html"><a href="lifeycle.html#the-journal-of-open-source-software"><i class="fa fa-check"></i><b>7.1.2</b> The Journal of Open Source Software</a></li>
<li class="chapter" data-level="7.1.3" data-path="lifeycle.html"><a href="lifeycle.html#academic-journal-reviews"><i class="fa fa-check"></i><b>7.1.3</b> Academic Journal Reviews</a><ul>
<li class="chapter" data-level="7.1.3.1" data-path="lifeycle.html"><a href="lifeycle.html#primary-and-secondary-editors"><i class="fa fa-check"></i><b>7.1.3.1</b> Primary and Secondary Editors</a></li>
<li class="chapter" data-level="7.1.3.2" data-path="lifeycle.html"><a href="lifeycle.html#invited-and-mentored-submissions"><i class="fa fa-check"></i><b>7.1.3.2</b> Invited and Mentored Submissions</a></li>
</ul></li>
<li class="chapter" data-level="7.1.4" data-path="lifeycle.html"><a href="lifeycle.html#the-debian-system"><i class="fa fa-check"></i><b>7.1.4</b> The Debian System</a></li>
<li class="chapter" data-level="7.1.5" data-path="lifeycle.html"><a href="lifeycle.html#other-potential-models"><i class="fa fa-check"></i><b>7.1.5</b> Other Potential Models</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="lifeycle.html"><a href="lifeycle.html#software-life-cycle-considerations"><i class="fa fa-check"></i><b>7.2</b> Software Life Cycle Considerations</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="process.html"><a href="process.html"><i class="fa fa-check"></i><b>8</b> <span style="color:red;">The Review Process [SEEKING FEEDBACK]</span></a><ul>
<li class="chapter" data-level="8.1" data-path="process.html"><a href="process.html#self-eval"><i class="fa fa-check"></i><b>8.1</b> Self-Evaluation of Software Prior to Submission</a></li>
<li class="chapter" data-level="8.2" data-path="process.html"><a href="process.html#presub-comm"><i class="fa fa-check"></i><b>8.2</b> Pre-Submission Communication</a></li>
<li class="chapter" data-level="8.3" data-path="process.html"><a href="process.html#reviewers-selection"><i class="fa fa-check"></i><b>8.3</b> Reviewers / Selection</a><ul>
<li class="chapter" data-level="8.3.1" data-path="process.html"><a href="process.html#database-of-potential-reviewers"><i class="fa fa-check"></i><b>8.3.1</b> Database of Potential Reviewers</a></li>
<li class="chapter" data-level="8.3.2" data-path="process.html"><a href="process.html#automating-the-identification-of-potential-reviewers"><i class="fa fa-check"></i><b>8.3.2</b> Automating the Identification of Potential Reviewers</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="process.html"><a href="process.html#submission-phase"><i class="fa fa-check"></i><b>8.4</b> Submission</a></li>
<li class="chapter" data-level="8.5" data-path="process.html"><a href="process.html#initial-screening"><i class="fa fa-check"></i><b>8.5</b> Initial Screening</a></li>
<li class="chapter" data-level="8.6" data-path="process.html"><a href="process.html#review-process"><i class="fa fa-check"></i><b>8.6</b> Review Process</a><ul>
<li class="chapter" data-level="8.6.1" data-path="process.html"><a href="process.html#review-templates"><i class="fa fa-check"></i><b>8.6.1</b> Review Templates</a></li>
<li class="chapter" data-level="8.6.2" data-path="process.html"><a href="process.html#review-comments"><i class="fa fa-check"></i><b>8.6.2</b> Review Comments</a></li>
<li class="chapter" data-level="8.6.3" data-path="process.html"><a href="process.html#category-specific-aspects-of-reviews"><i class="fa fa-check"></i><b>8.6.3</b> Category-Specific Aspects of Reviews</a></li>
<li class="chapter" data-level="8.6.4" data-path="process.html"><a href="process.html#reviewer-recommendations"><i class="fa fa-check"></i><b>8.6.4</b> Reviewer Recommendations</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="process.html"><a href="process.html#review-acceptance"><i class="fa fa-check"></i><b>8.7</b> Acceptance / Scoring / Badging</a></li>
<li class="chapter" data-level="8.8" data-path="process.html"><a href="process.html#post-acceptance-dissemination-publication-etc."><i class="fa fa-check"></i><b>8.8</b> Post-acceptance Dissemination, Publication, etc.</a></li>
<li class="chapter" data-level="8.9" data-path="process.html"><a href="process.html#ongoing-maintenance"><i class="fa fa-check"></i><b>8.9</b> Ongoing Maintenance</a></li>
<li class="chapter" data-level="8.10" data-path="process.html"><a href="process.html#structured-review-beyond-acceptance"><i class="fa fa-check"></i><b>8.10</b> Structured Review beyond Acceptance</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendices.html"><a href="appendices.html"><i class="fa fa-check"></i><b>A</b> Appendices</a><ul>
<li class="chapter" data-level="A.1" data-path="appendices.html"><a href="appendices.html#python"><i class="fa fa-check"></i><b>A.1</b> Notes on Scope and the Python Statistical Ecosystem</a></li>
<li class="chapter" data-level="A.2" data-path="appendices.html"><a href="appendices.html#appendix-keywords"><i class="fa fa-check"></i><b>A.2</b> Analysis of statistical software keywords</a></li>
<li class="chapter" data-level="A.3" data-path="appendices.html"><a href="appendices.html#other-software-standards"><i class="fa fa-check"></i><b>A.3</b> Other Software Standards</a></li>
<li class="chapter" data-level="A.4" data-path="appendices.html"><a href="appendices.html#bibliography"><i class="fa fa-check"></i><b>A.4</b> Bibliography</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Made with bookdown</a></li>
#download: [pdf]

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">rOpenSci Statistical Software Peer Review</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="scope" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Scope</h1>
<p>One task in extending the rOpenSci peer review system to statistical software
is defining <em>scope</em> - what software is included or excluded. Defining scope
requires some grouping of packages into categories. These categories play key
roles in the peer review process and standards-setting.</p>
<ol style="list-style-type: decimal">
<li>Categorical definitions can determine which kinds of software will be admitted;</li>
<li>Different categories of software will be subject to different standards, so
categories are key to developing standards, review guidance, and automated
testing.</li>
</ol>
<p>Creating a categorization or ontology of statistical software can easily become
an overwhelming project in itself. Here we attempt to derive categories or
descriptors which are <em>practically useful</em> in the standards and review process,
rather than a formally coherent system. We use a mix of empirical
research on common groupings of software and subjective judgement as to their
use in the review process.</p>
<p>We consider two main types of categories:</p>
<ol style="list-style-type: decimal">
<li>Categories of software structure, referred to as “software types”,
determined by computer languages and package formats in those languages; and</li>
<li>Categories defining different types of statistical software, referred to as
“statistical categories”.</li>
</ol>
<div id="software-types" class="section level2">
<h2><span class="header-section-number">4.1</span> Software types</h2>
<div id="languages" class="section level3">
<h3><span class="header-section-number">4.1.1</span> Languages</h3>
<p>This project extends an existing software peer-review process run by
<a href="https://ropensci.org">rOpenSci</a>, and is primarily intended to target the <strong>R</strong>
language. Nonetheless, given the popularity of Python in the field (see
relevant analyses and notes in <a href="appendices.html#python">Appendix A</a>), the impact of developing
standards applicable to Python packages must be considered. rOpenSci also has
a close collaboration with its sister organization,
<a href="https://www.pyopensci.org">pyOpenSci</a>.</p>
<p>In addition it is particularly important to note that many <strong>R</strong> packages
include code from a variety of other languages. The following table summarises
statistics for the top ten languages from all 15,735 <a href="https://cran.r-project.org">CRAN</a> packages as of 13 Oct 2020
(including only code from the <code>/R</code>, <code>/src</code>, and <code>/inst</code> directories of each
package).</p>
<table>
<caption><span id="tab:language-table">Table 4.1: </span>Proportion of code lines in different languages in all CRAN packages.</caption>
<thead>
<tr class="header">
<th align="left">language</th>
<th align="left">lines</th>
<th align="right">proportion</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">R</td>
<td align="left">22,559,154</td>
<td align="right">0.441</td>
</tr>
<tr class="even">
<td align="left">C/C++ Header</td>
<td align="left">6,751,884</td>
<td align="right">0.132</td>
</tr>
<tr class="odd">
<td align="left">HTML</td>
<td align="left">5,558,181</td>
<td align="right">0.109</td>
</tr>
<tr class="even">
<td align="left">C</td>
<td align="left">5,094,263</td>
<td align="right">0.100</td>
</tr>
<tr class="odd">
<td align="left">C++</td>
<td align="left">4,671,645</td>
<td align="right">0.091</td>
</tr>
<tr class="even">
<td align="left">JavaScript</td>
<td align="left">1,473,084</td>
<td align="right">0.029</td>
</tr>
<tr class="odd">
<td align="left">Fortran 77</td>
<td align="left">822,194</td>
<td align="right">0.016</td>
</tr>
<tr class="even">
<td align="left">JSON</td>
<td align="left">762,253</td>
<td align="right">0.015</td>
</tr>
<tr class="odd">
<td align="left">CSS</td>
<td align="left">638,341</td>
<td align="right">0.012</td>
</tr>
<tr class="even">
<td align="left">Rmd</td>
<td align="left">548,011</td>
<td align="right">0.011</td>
</tr>
</tbody>
</table>
<p>Close to one half of all code in all R packages to date has been written in the
R language, clearly justifying a primary focus upon that language. Collating
all possible ways of packaging and combining C and C++ code yields
16,517,792 lines or code or
32% of all code, indicating that
76% of all code has been
written in either R or C/C++. Three of these top ten languages are likely
related to web-based output (HTML, JavaScript, and CSS), representing a total
of 15% of all code. While this is
clearly a significant proportion, and while this <em>may</em> reflect an equivalent
high frequency of code devoted to some form of web-based visualisation, these
statistics represent <em>all</em> R packages. In many cases this represents extensive
headers in supplementary documentation. There is no simple way to identify which
of these might be considered statistical code in web-based languages, but knowing that there are
packages exclusively constructed to generate web-based visualisations and documentation in
a generic sense suggests that this value may be taken as an upper limit on
the likely frequency of these types of visualisation packages (or parts thereof) in the
context of statistical software.</p>
<p><strong><em>Key considerations</em></strong>:</p>
<ul>
<li>Expansion into the Python ecosystem has great potential for impact, but goes
beyond the general areas of expertise in the core ecosystem. (And Python code
represents just
157,814
lines of code, or
0.3%
of all code within all R packages.)</li>
<li>Compiled languages within R packages are core to many statistical
applications; excluding them would exclude core functionality the project
aims to addressed. The majority of compiled code is nevertheless C and/or
C++, with Fortran representing under 2% of all code.</li>
<li>Languages used for web-based visualisations comprise a significant proportion
(15%) of all code. While this
potentially indicates a likely importance of visualisation routines, this
figure reflects general code in all R packages, and the corresponding
proportion within the specific context of statistical software may be
considerably lower.</li>
<li>Any decision to include visualisation software and routines within our scope
will likely entail an extension of linguistic scope to associated languages
(HTML, JavaScript, and maybe CSS).</li>
</ul>
</div>
<div id="structure" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Structure</h3>
<p>R has a <a href="https://cran.r-project.org/doc/manuals/R-exts.html">well-defined
system</a> for structuring
software packages" Other forms of packaging <strong>R</strong> software may nevertheless be
considered within scope. These may include</p>
<ol style="list-style-type: decimal">
<li>Python-like systems of <a href="https://github.com/klmr/modules">modules for <strong>R</strong></a>;</li>
<li>Packaging appropriate for other languages (such as Python) yet with some
interface with the R language;</li>
<li>R interfaces (“wrappers”) to algorithms or software developed independently
in different languages, and which may or may not be bundled as a standard
R package; and</li>
<li>Web applications such as Shiny packages.</li>
</ol>
<p><strong>Key considerations</strong>: Allowing non-package forms of code into the peer review
system could potentially bring in a large pool of code typically published
alongside scientific manuscripts, and web applications are a growing, new area
of practice. However, there is far less standardization of code structure to
allow for style guidelines and automated testing in these cases.</p>
</div>
</div>
<div id="scope-categories-bg" class="section level2">
<h2><span class="header-section-number">4.2</span> Statistical Categories – Background</h2>
<p>As alluded to at the outset of this chapter, a primary task of this project
will be to categorise statistical software in order to:</p>
<ul>
<li>Determine the extent to which software fits within scope</li>
<li>Enable fields of application of software to be readily identified</li>
<li>Enable determination of applicable standards and assessment procedures</li>
<li>Enable discernment of appropriate reviewers</li>
</ul>
<p>Any piece of statistical software need not necessarily be described by a single
category, rather the categories proposed below are intended to serve as
a checklist, with submitting authors ticking <em>all</em> applicable categories.
A software submission will then be assessed with reference to the set of
Standards and Assessment Procedures (S&amp;APs) corresponding to all categories
describing that software.</p>
<p>Our definition of categories is particularly guided by a need to develop
applicable S&amp;APs. Each of the categories that follow has accordingly been
proposed because it has been judged to reflect a domain within which S&amp;APs are
likely to be both unique and important. These categories are not intended to
reflect an attempt to define <em>statistical software</em> in general, rather an
attempt to define areas in which S&amp;APs for statistical software may be
productively developed and applied.</p>
<p>We anticipate throughout our development of S&amp;APs that aspects will emerge
which are common to several categories. It may be deemed to elevate such S&amp;APs
to general procedures (largely) independent of specific categories. More
generally, although we aim for category-specific S&amp;APs which are as independent
of the other categories as possible, S&amp;APs in any one category will often be
related to those from other categories, and co-development of procedures in
multiple categories may be necessary.</p>
<div id="empirical-derivation-of-categories" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Empirical Derivation of Categories</h3>
<p>We attempted to derive a realistic categorisation through using empirical data
from several sources of potential software submissions, including all
apparently “statistical” R packages published in the <a href="https://joss.theoj.org">Journal of Open Source
Software (JOSS</a>), packages published in the <a href="https://www.jstatsoft.org/index">Journal of
Statistical Software</a>, software presented at
the 2018 and 2019 Joint Statistical Meetings (JSM), and Symposia on Data
Science and Statistics (SDSS), well as CRAN task views. We have also compiled
a list of the descriptions of <a href="https://github.com/mpadge/statistical-software/blob/master/abstracts/ropensci-abstracts.md">all packages rejected by
rOpenSci</a>
as being out of current scope because of current inability to consider
statistical packages, along with a selection of <a href="https://github.com/mpadge/statistical-software/blob/master/abstracts/joss-abstracts.md">recent statistical
R packages</a>
accepted by JOSS. (The full list of all R package published by JOSS can be
viewed at <a href="https://joss.theoj.org/papers//in/R" class="uri">https://joss.theoj.org/papers//in/R</a>).</p>
<p>We allocated one or more key words (or phrases) to each abstract, and use the
frequencies and inter-connections between these to inform the following
categorisation are represented in the <a href="https://ropenscilabs.github.io/statistical-software/abstracts/network-terms/index.html">interactive
graphic</a>
(also included in the <a href="appendices.html#appendix-keywords">Appendix</a>), itself derived from
analyses of abstracts from all statistical software submitted to both rOpenSci
and JOSS. (Several additional analyses and graphical representations of these
raw data are included an <a href="https://github.com/ropenscilabs/statistical-software">auxiliary github
repository</a>.) The primary
nodes that emerge from these empirical analyses (with associated <em>relative</em>
sizes in parentheses) are shown in the following table.</p>
<table>
<caption><span id="tab:top-terms">Table 4.2: </span>Most frequent key words from all JOSS abstracts (N = 92) for statistical software. Proportions are scaled <em>per abstract</em>, with each abstract generally having multiple key words, and so sum of proportions exceeds one.</caption>
<thead>
<tr class="header">
<th align="right">n</th>
<th align="left">term</th>
<th align="right">proportion</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="left">ML</td>
<td align="right">0.133</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="left">statistical indices and scores</td>
<td align="right">0.111</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="left">visualization</td>
<td align="right">0.111</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="left">dimensionality reduction</td>
<td align="right">0.100</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="left">probability distributions</td>
<td align="right">0.100</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="left">regression</td>
<td align="right">0.100</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="left">wrapper</td>
<td align="right">0.100</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="left">estimates</td>
<td align="right">0.089</td>
</tr>
<tr class="odd">
<td align="right">9</td>
<td align="left">Monte Carlo</td>
<td align="right">0.089</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="left">Bayesian</td>
<td align="right">0.078</td>
</tr>
<tr class="odd">
<td align="right">11</td>
<td align="left">categorical variables</td>
<td align="right">0.078</td>
</tr>
<tr class="even">
<td align="right">12</td>
<td align="left">EDA</td>
<td align="right">0.078</td>
</tr>
<tr class="odd">
<td align="right">13</td>
<td align="left">networks</td>
<td align="right">0.078</td>
</tr>
<tr class="even">
<td align="right">14</td>
<td align="left">summary statistics</td>
<td align="right">0.067</td>
</tr>
<tr class="odd">
<td align="right">15</td>
<td align="left">survival</td>
<td align="right">0.067</td>
</tr>
<tr class="even">
<td align="right">16</td>
<td align="left">workflow</td>
<td align="right">0.067</td>
</tr>
</tbody>
</table>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<p>The top key words and their inter-relationships within the main <a href="https://ropenscilabs.github.io/statistical-software/abstracts/network-terms/index.html">network
diagram</a>
were used to distinguish the following primary categories representing all
terms which appear in over 5% of all abstracts, along with the two additional
categories of “spatial” and “education”. We have excluded the key word
“Estimates” as being too generic to usefully inform standards, and have also
collected a few strongly-connected terms into single categories.</p>
<table>
<caption><span id="tab:methods-categories">Table 4.3: </span>Proposed categorisation of statistical software, with corresponding proportions of all JOSS software matching each category</caption>
<colgroup>
<col width="1%" />
<col width="18%" />
<col width="4%" />
<col width="76%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">n</th>
<th align="left">term</th>
<th align="right">proprtion</th>
<th align="left">comment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="left">Bayesian &amp; Monte Carlo</td>
<td align="right">0.167</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="left">dimensionality reduction &amp; feature selection</td>
<td align="right">0.144</td>
<td align="left">Commonly as a result of ML algorithms</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="left">ML</td>
<td align="right">0.133</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="left">regression/splines/interpolation</td>
<td align="right">0.133</td>
<td align="left">Including function data analysis</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="left">statistical indices and scores</td>
<td align="right">0.111</td>
<td align="left">Software generally intended to produce specific indices or scores as statistical output</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="left">visualization</td>
<td align="right">0.111</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="left">probability distributions</td>
<td align="right">0.100</td>
<td align="left">Including kernel densities, likelihood estimates and estimators, and sampling routines</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="left">wrapper</td>
<td align="right">0.100</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="right">9</td>
<td align="left">categorical variables</td>
<td align="right">0.078</td>
<td align="left">Including latent variables, and those output from ML algorithms. Note also that method for dimensionality reduction (such as clustering) often transform data to categorical forms.</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="left">Exploratory Data Analysis (EDA)</td>
<td align="right">0.078</td>
<td align="left">Including information statistics such as Akaike’s criterion, and techniques such as random forests. Often related to workflow software.</td>
</tr>
<tr class="odd">
<td align="right">11</td>
<td align="left">networks</td>
<td align="right">0.078</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="right">12</td>
<td align="left">summary statistics</td>
<td align="right">0.067</td>
<td align="left">Primarily related in the empirical data to regression and survival analyses, yet clearly a distinct category of its own.</td>
</tr>
<tr class="odd">
<td align="right">13</td>
<td align="left">survival</td>
<td align="right">0.067</td>
<td align="left">strongly related to EDA, yet differing in being strictly descriptive of software <em>outputs</em> whereas EDA may include routines to explore data <em>inputs</em> and other pre-output stages of analysis.</td>
</tr>
<tr class="even">
<td align="right">14</td>
<td align="left">workflow</td>
<td align="right">0.067</td>
<td align="left">Often related to EDA, and very commonly also to ML.</td>
</tr>
<tr class="odd">
<td align="right">15</td>
<td align="left">spatial</td>
<td align="right">0.033</td>
<td align="left">Also an important intermediate node connecting several other nodes, yet defining its own distinct cluster reflecting a distinct area of expertise.</td>
</tr>
<tr class="even">
<td align="right">16</td>
<td align="left">education</td>
<td align="right">0.044</td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p>The full network diagram can then be reduced down to these categories only,
with interconnections weighted by all first- and second-order interconnections
between intermediate categories, to give the following, simplified diagram
(in which “scores” denotes “statistical indices and scores”; with the diagram
best inspected by dragging individual nodes to see their connections to
others).</p>
<pre><code>## `summarise()` regrouping output by &#39;from&#39; (override with `.groups` argument)
## `summarise()` regrouping output by &#39;from&#39; (override with `.groups` argument)</code></pre>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<div id="htmlwidget-52c3d47cbf43b992f199" style="width:672px;height:480px;" class="visNetwork html-widget"></div>
<script type="application/json" data-for="htmlwidget-52c3d47cbf43b992f199">{"x":{"nodes":{"label":["Bayes/MC","dimensionality reduction","ML","regression","scores","visualization","probability distributions","wrapper","categorical variables","EDA","networks","summary statistics","survival","workflow","education","spatial"],"value":[15,13,12,11,10,10,9,9,7,7,7,6,6,6,4,3],"id":["Bayes/MC","dimensionality reduction","ML","regression","scores","visualization","probability distributions","wrapper","categorical variables","EDA","networks","summary statistics","survival","workflow","education","spatial"]},"edges":{"from":["Bayes/MC","Bayes/MC","Bayes/MC","Bayes/MC","Bayes/MC","Bayes/MC","Bayes/MC","Bayes/MC","Bayes/MC","Bayes/MC","Bayes/MC","categorical variables","categorical variables","categorical variables","dimensionality reduction","dimensionality reduction","dimensionality reduction","dimensionality reduction","dimensionality reduction","dimensionality reduction","dimensionality reduction","EDA","EDA","EDA","EDA","EDA","EDA","EDA","education","education","education","education","education","education","education","ML","ML","ML","ML","ML","ML","ML","ML","networks","networks","probability distributions","regression","regression","scores","scores","summary statistics","summary statistics","summary statistics","survival","visualization","visualization","workflow"],"to":["EDA","education","ML","networks","regression","scores","spatial","summary statistics","survival","visualization","wrapper","ML","networks","scores","Bayes/MC","ML","regression","spatial","survival","visualization","workflow","education","ML","networks","summary statistics","visualization","workflow","wrapper","dimensionality reduction","ML","networks","summary statistics","visualization","workflow","wrapper","networks","probability distributions","regression","summary statistics","survival","visualization","workflow","wrapper","visualization","wrapper","regression","survival","visualization","visualization","workflow","visualization","workflow","wrapper","visualization","workflow","wrapper","wrapper"],"width":[5,5,5,5,5,5,5,5,5,5,5,2.36111111111111,2.36111111111111,2.36111111111111,3.88888888888889,3.88888888888889,3.88888888888889,3.88888888888889,3.88888888888889,3.88888888888889,3.88888888888889,2.77777777777778,2.77777777777778,2.77777777777778,2.77777777777778,2.77777777777778,2.77777777777778,2.77777777777778,1.66666666666667,1.66666666666667,1.66666666666667,1.66666666666667,1.66666666666667,1.66666666666667,1.66666666666667,2.5,2.5,2.5,2.5,2.5,2.5,2.5,2.5,0.972222222222222,0.972222222222222,0.555555555555556,1.66666666666667,1.66666666666667,0.694444444444444,0.694444444444444,0.694444444444444,0.694444444444444,0.694444444444444,0.277777777777778,0.416666666666667,0.416666666666667,0.138888888888889]},"nodesToDataframe":true,"edgesToDataframe":true,"options":{"width":"100%","height":"100%","nodes":{"shape":"dot"},"manipulation":{"enabled":false}},"groups":null,"width":null,"height":null,"idselection":{"enabled":false},"byselection":{"enabled":false},"main":null,"submain":null,"footer":null,"background":"rgba(0, 0, 0, 0)"},"evals":[],"jsHooks":[]}</script>
<p>Standards considered under any of the ensuing categories must be developed with
reference to inter-relationships between categories, and in particular to
potential ambiguity within and between any categorisation. An example of such
ambiguity, and of potential difficulties associated with categorisation, is the
category of “network” software which appropriate describes the
<a href="https://github.com/jakobbossek/grapherator"><code>grapherator</code></a> package (with
accompanying <a href="https://joss.theoj.org/papers/10.21105/joss.00528">JOSS paper</a>)
which is effectively a distribution generator for data represented in
a particular format that happens to represent a graph; and three JSM
presentations, one on <a href="https://ww2.amstat.org/meetings/jsm/2018/onlineprogram/AbstractDetails.cfm?abstractid=327171">network-based clustering of high-dimensional
data</a>,
one on <a href="https://ww2.amstat.org/meetings/jsm/2018/onlineprogram/AbstractDetails.cfm?abstractid=328764">community structure in dynamic
networks</a>
and one on <a href="https://ww2.amstat.org/meetings/jsm/2018/onlineprogram/AbstractDetails.cfm?abstractid=328764">Gaussian graphical
models</a>.
Standards derived for network software must accommodate such diversity of
applications, and must accommodate software for which the “network” category
may pertain only to some relatively minor aspect, while the primary algorithms
or routines may not be related to network software in any direct way.</p>
</div>
<div id="examples-of-statistical-software" class="section level3">
<h3><span class="header-section-number">4.2.2</span> Examples of Statistical Software</h3>
<p>We now consider a few brief categorical examples, to illustrate the kinds of
decisions such a process of categorisation will likely face.</p>
<hr />
<ul>
<li><p><a href="https://github.com/ropensci/software-review/issues/334"><strong>gtsummary</strong></a>,
submitted to rOpenSci and reject as out-of-scope.</p>
<p>Creates presentation-ready tables summarizing data sets, regression models,
and more. The code to create the tables is concise and highly
customizable. Data frames can be summarized with any function,
e.g. mean(), median(), even user-written functions. Regression models are
summarized and include the reference rows for categorical variables.
Common regression models, such as logistic regression and Cox proportional
hazards regression, are automatically identified and the tables are
pre-filled with appropriate column headers.</p>
<p>This package appears not to contain any algorithmic implementations, yet is
clearly aimed at enhancing a purely statistical workflow. Such a submission
requires answering the question of whether software categorized as
“workflow” only and which does not correspond to any other of the above
categories, may be deemed in scope?</p></li>
</ul>
<hr />
<ul>
<li><p><a href="https://joss.theoj.org/papers/10.21105/joss.01601">greta: simple and scalable statistical modelling in
R</a>, published in JOSS.</p>
<p>greta is an package for statistical modelling in R (R Core Team, 2019) that
has three core differences to commonly used statistical modelling software
packages:</p>
<ul>
<li><p>greta models are written interactively in R code rather than in a
&gt; compiled domain specific language.</p></li>
<li><p>greta can be extended by other R packages; providing a fully-featured
&gt; package management system for extensions.</p></li>
<li><p>greta performs statistical inference using TensorFlow (Abadi et al.,
&gt; 2015), enabling it to scale across modern high-performance computing
&gt; systems.</p></li>
</ul>
<p>The <code>greta</code> package might be considered predominantly an interface to
TensorFlow, yet it provides a new way to specify and work with purely
statistical models. This might be considered under both workflow and wrapper
categories, and serves here to illustrate the question of whether wrappers
around, in this case, externally-installed software might be considered in
scope? And if so, to what extent ought aspects of such externally-installed
software also be directly addressed within a review process?</p></li>
</ul>
<hr />
<ul>
<li><p><a href="https://joss.theoj.org/papers/10.21105/joss.01798"><strong>modelStudio</strong></a>,
published in JOSS.</p>
<p>The <code>modelStudio</code> R package automates the process of model exploration. It
generates advanced interactive and animated model explanations in the form
of a serverless HTML site. It combines R(R Core Team, 2019) with D3.js
(Bostock, 2016) to produce plots and descriptions for various local and
global explanations. Tools for model exploration unite with tools for EDA
to give a broad overview of the model behaviour.</p>
<p>As with <code>gtsummary</code> above, this is clearly a package intended to enhance a
workflow, and furthermore one which primarily serves to generate summary
output as a <code>html</code> document, yet the models it considers, and all aspects
of output produced, are purely statistical. This package could meet both
workflow and visualization categories, and serves here to illustrate
difficulties in considering the latter of these. The <code>D3.js</code> library
contains numerous indubitably statistical routines, and so this package
might be argued to be a wrapper in the same category as <code>greta</code> is a wrapper
around <code>TensorFlow</code>. An important question likely to arise in considering
both of these is the extent to which the library being wrapped should also
be <em>predominantly statistical</em> for a package to be in scope? (A requirement
which <code>greta</code> would more easily fulfil than <code>gtsummary</code>.)</p></li>
</ul>
</div>
</div>
<div id="scope-categories" class="section level2">
<h2><span class="header-section-number">4.3</span> Statistical Categories</h2>
<p>Based on the preceding categories, along with contributions via our <a href="https://discuss.ropensci.org/t/statistical-software-peer-review-categories/2068">discussion
forum</a>,
we propose the following categories intended by define and guide the assessment
of statistical software. These categories are intended to serve as checklist
items, with each submission likely to check several categories. The categories are:</p>
<ol style="list-style-type: decimal">
<li><a href="scope.html#scope-category-bayesian">Bayesian and Monte Carlo Routines</a></li>
<li><a href="scope.html#scope-category-unsupervised">Dimensionality Reduction, Clustering, and Unsupervised Learning</a></li>
<li><a href="scope.html#scope-category-ML">Machine Learning</a></li>
<li><a href="scope.html#scope-category-supervised">Regression and Supervised Learning</a></li>
<li><a href="scope.html#scope-category-distributions">Probability Distributions</a></li>
<li><a href="scope.html#scope-category-wrapper">Wrapper Packages</a></li>
<li><a href="scope.html#scope-category-networks">Networks</a></li>
<li><a href="scope.html#scope-category-EDA">Exploratory Data Analysis (EDA) and Summary Statistics</a></li>
<li><a href="scope.html#scope-category-workflow">Workflow Support</a></li>
<li><a href="scope.html#scope-category-spatial">Spatial Analyses</a></li>
<li><a href="scope.html#scope-category-time">Time Series Analyses</a></li>
</ol>
<div id="scope-category-bayesian" class="section level3">
<h3><span class="header-section-number">4.3.1</span> Bayesian and Monte Carlo Routines</h3>
<p>Packages implementing or otherwise relying on Bayesian or Monte Carlo routines
represent form the central “hub” of all categories in the above diagram,
indicating that even though this category is roughly equally common to other
categories, software in this category is more likely to share more other
categories. In other words, this is the leading “hybrid” category within which
standards for all other categories must also be kept in mind. Some examples of
software in this category include:</p>
<ol style="list-style-type: decimal">
<li>The <a href="https://joss.theoj.org/papers/10.21105/joss.01541"><code>bayestestR</code>
package</a> “provides tools
to describe … posterior distributions”</li>
<li>The <a href="https://joss.theoj.org/papers/10.21105/joss.01143"><code>ArviZ</code> package</a> is
a python package for exploratory analyses of Bayesian models, particularly
posterior distributions.</li>
<li>The <a href="https://joss.theoj.org/papers/10.21105/joss.00216"><code>GammaGompertzCR</code>
package</a> features
explicit diagnostics of MCMC convergence statistics.</li>
<li>The <a href="https://joss.theoj.org/papers/10.21105/joss.00425"><code>BayesianNetwork</code>
package</a> is in many ways
a wrapper package primarily serving a <code>shiny</code> app, but also accordingly
a package in both education and EDA categories.</li>
<li>The <a href="https://joss.theoj.org/papers/10.21105/joss.01427"><code>fmcmc</code> package</a> is
a “classic” MCMC package which directly provides its own implementation, and
generates its own convergence statistics.</li>
<li>The <a href="https://joss.theoj.org/papers/10.21105/joss.00739"><code>rsimsum</code> package</a>
is a package to “summarise results from Monte Carlo simulation studies”.
Many of the statistics generated by this package may prove useful in
assessing and comparing Bayesian and Monte Carlo software in general. (See
also the <a href="https://joss.theoj.org/papers/10.21105/joss.00640"><code>MCMCvis</code>
package</a>, with more of
a focus on visualisation.)</li>
<li>The <a href="https://joss.theoj.org/papers/10.21105/joss.00061"><code>walkr</code> package</a> for
“MCMC Sampling from Non-Negative Convex Polytopes” is indicative of the
difficulties of deriving generally applicable assessments of software in
this category, because MCMC <em>sampling</em> relies on fundamentally different
inputs and outputs than many other MCMC routines.</li>
</ol>
<p><strong><em>Key Considerations</em></strong></p>
<ul>
<li>The extent to which the output of Bayesian routines with uninformative prior inputs can or do
reflect equivalent frequentist analyses.</li>
<li>Ways to standardise and compare diagnostic statistics for convergence of MCMC
routines.</li>
<li>Forms and structures of data using in these routines are very variable,
likely making comparison among algorithms difficult.</li>
</ul>
</div>
<div id="scope-category-unsupervised" class="section level3">
<h3><span class="header-section-number">4.3.2</span> Dimensionality Reduction, Clustering, and Unsupervised Learning</h3>
<p>Many packages either implement or rely upon techniques for dimensionality
reduction or feature selection. One of the primary problems presented by such
techniques is that they are constrained to yield a result independent on any
measure of correctness of accuracy <span class="citation">(Estivill-Castro <a href="#ref-estivill-castro_why_2002" role="doc-biblioref">2002</a>)</span>. This can make
assessment of the accuracy or reliability of such routines difficult. Moreover,
dimensionality reduction techniques are often developed for particular kinds of
input data, reducing abilities to compare and contrast different
implementations, as well as to compare them with any notional reference
implementations.</p>
<ol style="list-style-type: decimal">
<li><a href="https://joss.theoj.org/papers/10.21105/joss.01596"><code>ivis</code></a> implements
a dimensionality reduction technique using a "Siamese Neural Network
architecture.</li>
<li><a href="https://joss.theoj.org/papers/10.21105/joss.01279"><code>tsfeaturex</code></a> is
a package to automate “time series feature extraction,” which also provides
an example of a package for which both input and output data are generally
incomparable with most other packages in this category.</li>
<li><a href="https://joss.theoj.org/papers/10.21105/joss.01077"><code>iRF</code></a> is another
example of a generally incomparable package within this category, here one
for which the features extracted are the most distinct predictive features
extracted from repeated iterations of random forest algorithms.</li>
<li><a href="https://joss.theoj.org/papers/10.21105/joss.00967"><code>compboost</code></a> is
a package for component-wise gradient boosting which may be sufficient
general to potentially allow general application to problems addressed by
several packages in this category.</li>
<li>The <a href="https://joss.theoj.org/papers/10.21105/joss.00786"><code>iml</code></a> package may
offer usable functionality for devising general assessments of software
within this category, through offering a “toolbox for making machine
learning models interpretable” in a “model agnostic” way.</li>
</ol>
<p><strong><em>Key Considerations</em></strong></p>
<ul>
<li>It is often difficult to discern the accuracy of reliability of
dimensionality reduction techniques.</li>
<li>It is difficult to devise general routines to compare and assess different
routines in this category, although possible starting points for the
development of such may be offered by the
<a href="https://joss.theoj.org/papers/10.21105/joss.00967"><code>compboost</code></a> and
<a href="https://joss.theoj.org/papers/10.21105/joss.00786"><code>iml</code></a> packages.</li>
</ul>
</div>
<div id="scope-category-ML" class="section level3">
<h3><span class="header-section-number">4.3.3</span> Machine Learning</h3>
<p>Machine Learning (ML) routines play a central role in modern statistical
analyses, and the ML node in the above diagram is roughly equally central,
and equally connected, to the Bayesian and Monte Carlo node. Machine Learning
algorithms represent perhaps some of the most difficult algorithms for which to
develop standards and methods of comparison. Both input and output data can be
categorically different or even incomparable, while even where these may be
comparable, the abiding aims of different ML algorithms can differ sufficiently
to make comparison of outputs to otherwise equivalent inputs largely
meaningless. A few potentially fruitful routes towards productive comparison
may nevertheless be discerned, here according to the sub-domains of input data,
output data, and algorithms.</p>
<p><strong><em>Input Data</em></strong> One promising R package which may prove very useful for
standardising and comparing data used as input to ML algorithms is the
<a href="https://joss.theoj.org/papers/10.21105/joss.00584"><code>vtreat</code></a> package that
“prepares messy real world data for predictive modeling in a reproducible and
statistically sound manner.” The routines in this package perform a series of
tests for general sanity of input data, and may prove generally useful as part
of a recommended ML workflow.</p>
<p><strong><em>Algorithms</em></strong> A number of packages attempt to offer unified interfaces to
a variety of ML algorithms, and so may be used within the context of the
present project either as potential recommended standards, or as ways by which
different algorithms may be compared within a standard workflow. Foremost among
such packages are
<a href="https://joss.theoj.org/papers/10.21105/joss.01903"><code>mlr3</code></a>, which represents
one of the core R packages for ML, developed by the key developers of previous
generations of ML software in R. It offers a modular and extensible interface
for a range of ML routines, and may prove very useful in comparing different ML
routines and implementations.</p>
<p><strong><em>Output Data</em></strong> There are several extant packages for (post-)processing data
output from ML algorithms. Many, perhaps even most, of these primarily aim to
derive insightful visualisations of output, whether in interactive
(JavaScript-based) form, as with the
<a href="https://joss.theoj.org/papers/10.21105/joss.01798"><code>modelStudio</code></a> or
<a href="https://joss.theoj.org/papers/10.21105/joss.01444"><code>modelDown</code></a> packages, or
more static plots using internal graphical routines from R, as in the <a href="https://joss.theoj.org/papers/10.21105/joss.00786"><code>iml</code>
(Interpretable Machine
Learning)</a> package. The
latter package offers a host of additional functionality useful in interpreting
the output of ML algorithms, and which may prove useful in general
standards-based contexts.</p>
<p>Potential “edge cases” which may be difficult to reconcile with the general
aspects described above include the following:</p>
<ol style="list-style-type: decimal">
<li><a href="https://joss.theoj.org/papers/10.21105/joss.01087"><code>ReinforcementLearning</code></a>
is a simulation package employing ML routines to enable agents to learn
through trial and error. It is an example of a package with inputs and
outputs which may be difficult to compare with other ML software, and
difficult to assess via general standards.</li>
<li><a href="https://joss.theoj.org/papers/10.21105/joss.01193"><code>BoltzMM</code></a> is an
implementation of a particular class of ML algorithms (“Boltmann Machines”),
and so provides an obverse example to the above, for which in this case
inputs and outputs may be compared in standard ways, yet the core algorithm
may be difficult to compare.</li>
<li><a href="https://joss.theoj.org/papers/10.21105/joss.01036"><code>dml</code></a> is a collection
of different ML algorithms which perform the same task (“distance metric
learning”). While comparing algorithms <em>within</em> the package is obviously
straightforward, comparison in terms of external standards may not be.</li>
</ol>
</div>
<div id="scope-category-supervised" class="section level3">
<h3><span class="header-section-number">4.3.4</span> Regression and Supervised Learning</h3>
<p>This category represents the most important intermediate node in the above
network graphic between ML and Bayesian/Monte Carlo algorithms, as well as
being strongly connected to several other nodes. While many regression or
interpolation algorithms are developed as part of general frameworks within
these contexts, there are nevertheless sufficiently many examples of regression
and interpolation algorithms unrelated to these contexts to warrant the
existence of this distinct category. That said, algorithms within this category
share very little in common, and each implementation is generally devised for
some explicit applied purpose which may be difficult to relate to any other
implementations in this category.</p>
<p>Perhaps one feature which almost of the following examples share in common is
input and output data in (potentially multi-dimensional) vector format, very
generally (but not exclusively) in numeric form. This may be one category in
which the development of a system for <a href="#standards-testing">property-based
testing</a>, like the <a href="https://hypothesis.works"><code>hypothesis</code> framework for
python</a> may be particularly useful. Such a system
would facilitate tests in response to a range of differently input
<em>structures</em>, such as values manifesting different distributional properties.
Property-based testing is likely to be a particularly powerful technique for
uncovering faults in regression and interpolation algorithms.</p>
<p>Examples of the diversity of software in this category include the following.</p>
<ol style="list-style-type: decimal">
<li><a href="https://joss.theoj.org/papers/10.21105/joss.01761"><code>xrnet</code></a> to perform
“hierarchical regularized regression to incorporate external data”, where
“external data” in this case refers to structured meta-data as applied to
genomic features.</li>
<li><a href="https://joss.theoj.org/papers/10.21105/joss.01434"><code>survPen</code></a> is, “an
R package for hazard and excess hazard modelling with multidimensional
penalized splines”</li>
<li><a href="https://joss.theoj.org/papers/10.21105/joss.01221"><code>areal</code></a> is, “an
R package for areal weighted interpolation”.</li>
<li><a href="https://joss.theoj.org/papers/10.21105/joss.01287"><code>ChiRP</code></a> is a package
for “Chinese Restaurant Process mixtures for regression and clustering”,
which implements a class of non-parametric Bayesian Monte Carlo models.</li>
<li><a href="https://joss.theoj.org/papers/10.21105/joss.00722"><code>klrfome</code></a> is a package
for, “kernel logistic regression on focal mean embeddings,” with a specific
and exclusive application to the prediction of likely archaeological sites.</li>
<li><a href="https://joss.theoj.org/papers/10.21105/joss.01038"><code>gravity</code></a> is a package
for “estimation methods for gravity models in R,” where “gravity models”
refers to models of spatial interactions between point locations based on
the properties of those locations.</li>
<li><a href="https://joss.theoj.org/papers/10.21105/joss.00967"><code>compboost</code></a> is an
example of an R package for gradient boosting, which is inherently
a regression-based technique, and so standards for regression software
ought to consider such applications.</li>
<li><a href="https://joss.theoj.org/papers/10.21105/joss.00937"><code>ungroup</code></a> is, “an
R package for efficient estimation of smooth distributions from coarsely
binned data.” As such, this package is an example of regression-based
software for which the input data are (effectively) categorical. The
package is primarily intended to implement a particular method for
“unbinning” the data, and so represents a particular class of
interpolation methods.</li>
<li><a href="https://joss.theoj.org/papers/10.21105/joss.00557"><code>registr</code></a> is
a package for “registration for exponential family functional data,” where
registration in this context is effectively an interpolation method
applied within a functional data analysis context.</li>
</ol>
<p>One package which may be potential general use is the
<a href="https://joss.theoj.org/papers/10.21105/joss.00772"><code>ggeffects</code></a> package for
“tidy data frames of marginal effects from regression models.” This package
aims to make statistics quantifying marginal effects readily understandable,
and so implements a standard (tidyverse-based) methodology for representing and
visualising statistics relating to marginal effects.</p>
</div>
<div id="scope-category-distributions" class="section level3">
<h3><span class="header-section-number">4.3.5</span> Probability Distributions</h3>
<p>The category of probability distributions is an outlier in the preceding
network diagram, connected only to ML and regression/interpolation algorithms.
It is nevertheless included here as a distinct category because we anticipate
software which explicitly represents or relies on probability distributions to
be subject to distinct standards and assessment procedures, particularly
through enabling routines to be tested for robustness against a variety of
perturbations to assumed distributional forms.</p>
<p>Packages which fall within this category include:</p>
<ol style="list-style-type: decimal">
<li><a href="https://joss.theoj.org/papers/10.21105/joss.01863"><code>univariateML</code></a> which
is, “an R package for maximum likelihood estimation of univariate
densities,” which support more than 20 different forms of probability
density.</li>
<li><a href="https://joss.theoj.org/papers/10.21105/joss.01566"><code>kdensity</code></a> which is,
“An R package for kernel density estimation with parametric starts and
asymmetric kernels.” This package implements an effectively non-parametric
approach to estimating probability densities.</li>
<li><a href="https://joss.theoj.org/papers/10.21105/joss.01023"><code>overlapping</code></a>, which
is, “a R package for estimating overlapping in empirical distributions.”</li>
</ol>
<p>The obverse process from estimating or fitting probability distributions is
arguably drawing samples from defined distributions, of which the
<a href="https://joss.theoj.org/papers/10.21105/joss.00629"><code>humanleague</code></a> package is
an example. This package has a particular application in synthesis of discrete
populations, yet the implementation is quite generic and powerful.</p>
</div>
<div id="scope-category-wrapper" class="section level3">
<h3><span class="header-section-number">4.3.6</span> Wrapper Packages</h3>
<p>“Wrapper” packages provide an interface to previously-written software, often
in a different computer language to the original implementation. While this
category is reasonably unambiguous, there may be instances in which a “wrapper”
additionally offers extension beyond original implementations, or in which only
a portion of a package’s functionality may be “wrapped.” Rather than
internally bundling or wrapping software, a package may also serve as a wrapper
thorough providing access to some external interface, such as a web server.
Examples of potential wrapper packages include the following:</p>
<ol style="list-style-type: decimal">
<li>The
<a href="https://github.com/greta-dev/greta"><code>greta</code> package</a>
(with accompanying
<a href="https://joss.theoj.org/papers/10.21105/joss.01601">JOSS article</a>) “for
writing statistical models and fitting them by MCMC and optimisation”
provides a wrapper around google’s
<a href="https://www.tensorflow.org"><code>TensorFlow</code> library</a>. It is also clearly a workflow package, aiming to
provide a single, unified workflow for generic machine learning processes
and analyses.</li>
<li>The
<a href="https://github.com/keblu/nse"><code>nse</code> package</a> (with accompanying
<a href="https://joss.theoj.org/papers/10.21105/joss.00172">JOSS paper</a>) which
offers “multiple ways to calculate numerical standard errors (NSE) of
univariate (or multivariate in some cases) time series,” through providing
a unified interface to several other R packages to provide more than 30 NSE
estimators. This is an example of a wrapper package which does not wrap
either internal code or external interfaces, rather it effectively “wraps”
the algorithms of a collection of R packages.</li>
</ol>
<p><strong><em>Key Considerations</em></strong>: For many wrapper packages it may not be feasible
for reviewers (or authors) to evaluate the quality or correctness of the wrapped
software, so review could be limited to the interface or added value provided,
or the statistical routines within.</p>
<p>Wrapper packages include the extent of functionality represented by wrapped
code, and the computer language being wrapped.
- <em>Internal or External:</em> Does the software <em>internally</em> wrap of bundle
previously developed routines, or does it provide a wrapper around some
external service? If the latter, what kind of service (web-based, or some
other form of remote access)?
- <em>Language:</em> For internally-bundled routines, in which computer language
e the routines written? And how are they bundled? (For R packages: In
<code>./src</code>? In <code>./inst</code>? Elsewhere?)
- <em>Testing:</em> Does the software test the correctness of the wrapped component?
Does it rely on tests of the wrapped component elsewhere?
- <em>Unique Advances:</em> What unique advances does the software offer beyond
those offered by the (internally or externally) wrapped software?</p>
</div>
<div id="scope-category-networks" class="section level3">
<h3><span class="header-section-number">4.3.7</span> Networks</h3>
<p>Network software is a particular area of application of what might often be
considered more generic algorithms, as in the example described above of the
<a href="https://github.com/jakobbossek/grapherator"><code>grapherator</code></a> package, for which
this category is appropriate only because the input data are assumed to
represent a particular form of graphical relationship, while most of the
algorithms implemented in the package are not necessarily specific to graphs.
That package might nevertheless be useful in developing standards because it,
“implements a modular approach to benchmark graph generation focusing on
undirected, weighted graphs”. This package, and indeed several others developed
by its author <a href="http://www.jakobbossek.de/blog/">Jakob Bossek</a>, may be useful in
developing benchmarks for comparison of graph or network models and algorithms.</p>
<p>Cases of software which might be assessed using such generic graph generators
and benchmarks include:</p>
<ol style="list-style-type: decimal">
<li><a href="https://joss.theoj.org/papers/10.21105/joss.00374"><code>mcMST</code></a>, which is “a
toolbox for the multi-criteria minimum spanning tree problem.”</li>
<li><a href="https://joss.theoj.org/papers/10.21105/joss.00036"><code>gwdegree</code></a>, which is
a package for, “improving interpretation of geometrically-weighted degree
estimates in exponential random graph models.” This package essentially
generates one key graph statistic from a particular class of input graphs,
yet is clearly amenable to benchmarking, as well as measures of stability in
response to variable input structures.</li>
</ol>
<p>Network software which is likely more difficult to assess or compare in any
general way includes:</p>
<ol style="list-style-type: decimal">
<li><a href="https://joss.theoj.org/papers/10.21105/joss.01480"><code>tcherry</code></a> is a package
for “Learning the structure of tcherry trees,” which themselves are
particular ways of representing relationships between categorical data. The
package uses maximum likelihood techniques to find the best tcherry tree to
represent a given input data set. Although very clearly a form of network
software, this package might be considered better described by other
categories, and accordingly not directly assessed or assessable under any
standards derived for this category.</li>
<li><a href="https://www.bnlearn.com/"><code>BNLearn</code></a> is a package “for learning the
graphical structure of Bayesian networks.” It is indubitably a network
package, yet the domain of application likely renders it incomparable to
other network software, and difficult to assess in any standardised way.</li>
</ol>
</div>
<div id="scope-category-EDA" class="section level3">
<h3><span class="header-section-number">4.3.8</span> Exploratory Data Analysis (EDA) and Summary Statistics</h3>
<p>Many packages aim to simplify and facilitate the reporting of complex
statistical results or exploratory summaries of data. Such reporting commonly
involves visualisation, and there is direct overlap between this and the
Visualisation category (below). This roughly breaks out into software that
summarizes and presents <em>raw</em> data, and software that reports complex data
derived from statistical routines. However, this break is often not clean, as
raw data exploration may involve an algorithmic or modeling step (e.g.,
projection pursuit.). Examples include:</p>
<ol style="list-style-type: decimal">
<li>A package rejected by rOpenSci as out-of-scope,
<a href="https://github.com/ddsjoberg/gtsummary"><code>gtsummary</code></a>, which provides,
“Presentation-ready data summary and analytic result tables.” Other
examples include:</li>
<li>The <a href="https://github.com/daya6489/SmartEDA"><code>smartEDA</code> package</a> (with
accompanying <a href="https://joss.theoj.org/papers/10.21105/joss.01509">JOSS
paper</a>) “for automated
exploratory data analysis”. The package, “automatically selects the
variables and performs the related descriptive statistics. Moreover, it also
analyzes the information value, the weight of evidence, custom tables,
summary statistics, and performs graphical techniques for both numeric and
categorical variables.” This package is potentially as much a workflow
package as it is a statistical reporting package, and illustrates the
ambiguity between these two categories.</li>
<li>The <a href="https://github.com/ShanaScogin/modeLLtest"><code>modeLLtest</code> package</a> (with
accompanying <a href="https://joss.theoj.org/papers/10.21105/joss.01542">JOSS
paper</a>) is “An R Package
for Unbiased Model Comparison using Cross Validation.” Its main
functionality allows different statistical models to be compared, likely
implying that this represents a kind of meta package.</li>
<li>The <a href="https://github.com/easystats/insight"><code>insight</code> package</a> (with
accompanying <a href="https://joss.theoj.org/papers/10.21105/joss.01412">JOSS paper</a>
provides “a unified interface to access information from model objects in
R,” with a strong focus on unified and consistent reporting of statistical
results.</li>
<li>The <a href="https://github.com/arviz-devs/arviz"><code>arviz</code> software for python</a> (with
accompanying <a href="https://joss.theoj.org/papers/10.21105/joss.01143">JOSS paper</a>
provides “a unified library for exploratory analysis of Bayesian models in
Python.”</li>
<li>The <a href="https://github.com/sumbose/iRF"><code>iRF</code> package</a> (with accompanying <a href="https://joss.theoj.org/papers/10.21105/joss.01077">JOSS
paper</a> enables
“extracting interactions from random forests”, yet also focusses primarily
on enabling interpretation of random forests through reporting on
interaction terms.</li>
</ol>
<p>In addition to potential overlap with the Visualisation category, potential
standards for Statistical Reporting and Meta-Software are likely to overlap to
some degree with the preceding standards for Workflow Software. Checklist items
unique to statistical reporting software might include the following:</p>
<ul>
<li><input type="checkbox" disabled="" />
<strong>Automation</strong> Does the software automate aspects of statistical
reporting, or of analysis at some sufficiently “meta”-level (such as variable
or model selection), which previously (in a reference implementation)
required manual intervention?</li>
<li><input type="checkbox" disabled="" />
<strong>General Reporting:</strong> Does the software report on, or otherwise provide
insight into, statistics or important aspects of data or analytic processes
which were previously not (directly) accessible using reference
implementations?</li>
<li><input type="checkbox" disabled="" />
<strong>Comparison:</strong> Does the software provide or enable standardised
comparison of inputs, processes, models, or outputs which could previously
(in reference implementations) only be accessed or compared some comparably
unstandardised form?</li>
<li><input type="checkbox" disabled="" />
<strong>Interpretation:</strong> Does the software facilitate interpretation of
otherwise abstruse processes or statistical results?</li>
<li><input type="checkbox" disabled="" />
<strong>Exploration:</strong> Does the software enable or otherwise guide exploratory
stages of a statistical workflow?</li>
</ul>
</div>
<div id="scope-category-workflow" class="section level3">
<h3><span class="header-section-number">4.3.9</span> Workflow Support</h3>
<p>“Workflow” software may not implement particular methods or algorithms,
but rather support tasks around the statistical process. In many cases, these
may be generic tasks that apply across methods. These include:</p>
<ol style="list-style-type: decimal">
<li>Classes (whether explicit or not) for representing or processing input and
output data;</li>
<li>Generic interfaces to multiple statistical methods or algorithms;</li>
<li>Homogeneous reporting of the results of a variety of methods or algorithms;
and</li>
<li>Methods to synthesise, visualise, or otherwise collectively report on
analytic results.</li>
</ol>
<p>Methods and Algorithms software may only provide a specific interface to
a specific method or algorithm, although it may also be more general and offer
several of the above “workflow” aspects, and so ambiguity may often arise
between these two categories. We note in particular that the “workflow” node in
the
<a href="https://ropenscilabs.github.io/statistical-software/abstracts/network-terms">interactive network diagram</a>
mentioned above is very strongly connected to the “machine learning” node,
generally reflecting software which attempts to unify varied interfaces to
varied platforms for machine learning.</p>
<p>Among the numerous examples of software in this category are:</p>
<ol style="list-style-type: decimal">
<li>The
<a href="https://github.com/mlr-org/mlr3"><code>mlr3</code> package</a> (with accompanying
<a href="https://joss.theoj.org/papers/10.21105/joss.01903">JOSS paper</a>), which provides, “A modern object-oriented machine learning
framework in R.”</li>
<li>The
<a href="https://github.com/USCbiostats/fmcmc"><code>fmcmc</code> package</a>
(with accompanying
<a href="https://joss.theoj.org/papers/10.21105/joss.01427">JOSS paper</a>), which provides a unified framework and workflow for
Markov-Chain Monte Carlo analyses.</li>
<li>The
<a href="https://github.com/easystats/bayestestR"><code>bayestestR</code> package</a> (with accompanying
<a href="https://joss.theoj.org/papers/10.21105/joss.01541">JOSS paper</a>)
for "describing effects and their uncertainty, existence and significance
within the Bayesian framework. While this packages includes its own
algorithmic implementations, it is primarily intended to aid general
Bayesian workflows through a unified interface.</li>
</ol>
<p>Workflows are also commonly required and developed for specific areas of
application, as exemplified by the
<a href="https://github.com/nfrerebeau/tabula"><code>tabular</code> package</a> (with accompanying
<a href="https://joss.theoj.org/papers/10.21105/joss.01821">JOSS article</a> for “Analysis, Seriation, and visualisation of Archaeological
Count Data”.</p>
<p><strong><em>Key Considerations:</em></strong> Workflow packages are popular and add considerable value
and efficiency for users. One challenge in evaluating such packages is the
importance of API design and potential subjectivity of this. For instance,
<code>mlr3</code> as well as <code>tidymodels</code> have similar uses of providing a common interface
to multiple predictive models and tools for automating processes across these
models. Similar, multiple packages have different approaches for handling MCMC
data. Each package makes different choices in design and has different priorities,
which may or may not agree with reviewers’ opinions or applications. Despite such
differences, it may be possible to evaluate such packages for <em>internal</em> cohesion,
and adherence to a sufficiently clearly stated design goal. Reviewers may be able
to evaluate whether the package provides a <em>more</em> unified workflow or interface
than other packages - this would require a standard of relative improvement over
the field rather than baseline standards.</p>
<p>These packages also often contain numerical routines (cross-validation,
performance scoring, model comparison), that can be evaluated for correctness
or accuracy.</p>
</div>
<div id="scope-category-spatial" class="section level3">
<h3><span class="header-section-number">4.3.10</span> Spatial Analyses</h3>
<p>Spatial analyses have a long tradition in R, as summarised and reflected in the
CRAN Task Views on <a href="https://cran.r-project.org/web/views/Spatial.html">Spatial</a>
and <a href="https://cran.r-project.org/web/views/SpatioTemporal.html">Spatio-Temporal</a>
data and analyses. Those task views also make immediately apparent that the
majority of development in both of these domains has been in <em>representations</em>
of spatial data, rather than in statistical analyses <em>per se</em>.
Spatial statistical analyses have nevertheless been very strong in R, notably
through the <a href="https://cran.r-project.org/package=spatstat"><code>spatstat</code></a> and
<a href="https://cran.r-project.org/package=gstat"><code>gstat</code></a> packages, first published
in 2002 and 2003, respectively.</p>
<p>Spatial analyses entail a number of aspects which, while not necessarily unique
in isolation, when considered in combination offer sufficiently unique
challenges for this to warrant its own category. Some of these unique aspects
include:</p>
<ul>
<li>A generally firm embeddedness in two dimensions</li>
<li>Frequent assumptions of continuous rather than discrete processes
(point-pattern processes notwithstanding)</li>
<li>A pervasive decrease in statistical similarity with increasing distance - the
so-called “First Law of Geography” - which is the observe of pervasive
difficulties arising from auto-correlated observations.</li>
<li>A huge variety of statistical techniques such as kriging and triangulation
which have been developed for almost exclusive application in spatial
domains.</li>
<li>The unique challenges arising in the domain of <a href="https://cran.r-project.org/web/views/SpatioTemporal.html">Spatial Temporal
Analyses</a>.</li>
</ul>
</div>
<div id="scope-category-time" class="section level3">
<h3><span class="header-section-number">4.3.11</span> Time Series Analyses</h3>
<p>We will also consider time series software as a distinct category, owing to
unique ways of representing and processing such data.</p>
</div>
</div>
<div id="out-of-scope-categories" class="section level2">
<h2><span class="header-section-number">4.4</span> Out Of Scope Categories</h2>
<p>The following categories arise in the preceding empirical analyses, yet have
been deemed to lie beyond the scope of the project as currently envisioned.</p>
<div id="visualisation" class="section level3">
<h3><span class="header-section-number">4.4.1</span> Visualisation</h3>
<p>While many may consider software primarily aimed at visualisation to be out of
scope, there are nevertheless cases which may indeed be within scope, notably
including the
<a href="https://github.com/sinhrks/ggfortify"><code>ggfortify</code> package</a> which allows results of statistical tests to be
“automatically” visualised using the
<a href="https://ggplot2.tidyverse.org"><code>ggplot2</code> package</a>. The list of “fortified” functions on the packages
<a href="https://github.com/sinhrks/ggfortify">webpage</a> clearly indicates the very predominantly statistical scope of this
software which is in effect a package for statistical reporting, yet in visual
rather than tabular form. Other examples of visualisation software include:</p>
<ol style="list-style-type: decimal">
<li>The
<a href="https://github.com/ModelOriented/modelStudio"><code>modelStudio</code> package</a> (with accompanying
<a href="https://joss.theoj.org/papers/10.21105/joss.01798">JOSS paper</a>), which is also very much a workflow package.</li>
<li>The
<a href="https://github.com/PsyChiLin/EFAshiny"><code>shinyEFA</code> package</a> (with accompanying
<a href="https://joss.theoj.org/papers/10.21105/joss.00567">JOSS paper</a>) which provides a, “User-Friendly Shiny Application for
Exploratory Factor Analysis.”</li>
<li>The
<a href="https://github.com/terrytangyuan/autoplotly"><code>autoplotly</code> package</a> (with accompanying
<a href="https://joss.theoj.org/papers/10.21105/joss.00657">JOSS paper</a>) which provides, “Automatic Generation of Interactive
Visualisations for Statistical Results”, primarily by porting the output of
the authors’ above-mentioned
<a href="https://github.com/sinhrks/ggfortify"><code>ggfortify</code> package</a> to
<a href="https://github.com/plotly/plotly.js"><code>plotly.js</code></a>.</li>
</ol>
<p><strong><em>Key considerations</em></strong>: The quality or utility visualization techniques can
be strongly subjective, but also may be evaluated using standardized principles
if the community can come to a consensus on those principles. Such
considerations may be context-dependent - e.g., the requirements of
a diagnostic plot designed to support model-checking are different from that
designed to present raw data or model results to a new audience. This implies
that the intended purpose of the visualization should be well-defined.</p>
<p>Whether or not visualization is in-scope, many software packages with other
primary purposes also include functions to visualise output. Visualization will
thus never be <em>strictly</em> out of scope. However one option is not to include
<em>primarily</em> visualization packages, or only <em>statistical</em> visualization packages
in which visualization is closely tied to another category or purpose.</p>
<p>Visualisation packages will include numerical or statistical routines for
transforming data from raw form to graphics, which can be evaluated for correctness
or accuracy.</p>
</div>
<div id="education" class="section level3">
<h3><span class="header-section-number">4.4.2</span> Education</h3>
<p>A prominent class of statistical software is <em>educational</em> software designed to
teach statistics. Such software many include its own implementations of statistical
methods, and frequently include interactive components. Many examples of educational statistical software are
listed on the
<a href="https://cran.r-project.org/web/views/TeachingStatistics.html">CRAN Task View: Teaching Statistics</a>. This page also clearly indicates the
likely strong overlap between education and visualisation software. With
specific regard to the educational components of software, the follow checklist
items may be relevant.
A prominent example is the <a href="https://cran.r-project.org/web/packages/LearnBayes/index.html"><code>LearnBayes</code> package</a>.</p>
<p><strong><em>Key Considerations:</em></strong> Correctness of implementation of educational or tutorial
software is important. Evaluation of such software extends considerably beyond correctness,
with heavy emphasis on documentation, interactive interface, and pedagogical soundness
of the software. These areas enter a very different class of standards. It is
likely that educational software will very greatly <em>structurally</em>, as interaction
may be via graphical or web interfaces, text interaction or some other form.</p>
<p>The <a href="https://jose.theoj.org">Journal of Open Source Education</a> accepts both educational
software and curricula, and has a peer review system (almost)
identical to <a href="https://joss.theoj.org">JOSS</a>. Educational statistical software
reviewed by rOpenSci could thus potentially be fast-tracked through JOSE
reviews just as current submissions have the opportunity to be fast-tracked
through the JOSS review process.</p>
<ul>
<li><em>Demand:</em> Does the software meet a clear demand otherwise absent from
educational material? If so, how?</li>
<li><em>Audience:</em> What is the intended audience or user base? (For example,
is the software intended for direct use by students of statistics, or does it
provide a tool for educational professionals to use in their own practice?)</li>
<li><em>Algorithms:</em> What are the unique algorithmic processes implemented by
the software? In what ways are they easier, simpler, faster, or otherwise
better than reference implementations (where such exist)?</li>
<li><em>Interactivity:</em> Is the primary function of the software interactive?
If so, is the interactivity primarily graphical (for example, web-based),
text-based, or other?</li>
</ul>
</div>
</div>
<div id="proposals" class="section level2">
<h2><span class="header-section-number">4.5</span> Proposals</h2>
<ol style="list-style-type: decimal">
<li>Peer review in the system will primarily focus on code written in R, C, and
C++. Standards will be written so as to separate language-specific and
non-language-specific components with an eye towards further adoption by
other groups in the future (in particular groups focussed on the Python
language).</li>
<li>The system will be limited to R packages, and tools developed will be
specific to R package structure, although keeping in mind potential future
adaptation and adaptability to non-packaged R code. Standards that may apply
to non-packaged are code may also be noted for use in other contexts.</li>
<li>Submissions will be required to nominate at least one statistical category,
to nominate at least one “reference implementation”, and to explain how the
submitted software is superior (along with a possibility to explain why
software may be sufficiently unique that there is no reference
implementation, and so no claims of superiority can be made).</li>
<li>We will only review packages where the primary statistical functionality is
in the main source code developed by the authors, and not in an external
package.<br />
</li>
<li>The following 11 categories of statistical software be defined, and be
considered in scope:
<ul>
<li><ol style="list-style-type: decimal">
<li>Bayesian and Monte Carlo algorithms</li>
</ol></li>
<li><ol start="2" style="list-style-type: decimal">
<li>Dimensionality Reduction and Feature Selection</li>
</ol></li>
<li><ol start="3" style="list-style-type: decimal">
<li>Machine Learning</li>
</ol></li>
<li><ol start="4" style="list-style-type: decimal">
<li>Regression and Interpolation</li>
</ol></li>
<li><ol start="5" style="list-style-type: decimal">
<li>Probability Distributions</li>
</ol></li>
<li><ol start="6" style="list-style-type: decimal">
<li>Wrapper Packages</li>
</ol></li>
<li><ol start="7" style="list-style-type: decimal">
<li>Networks</li>
</ol></li>
<li><ol start="8" style="list-style-type: decimal">
<li>Exploratory Data Analysis</li>
</ol></li>
<li><ol start="9" style="list-style-type: decimal">
<li>Workflow Software</li>
</ol></li>
<li><ol start="10" style="list-style-type: decimal">
<li>Summary Statistics</li>
</ol></li>
<li><ol start="11" style="list-style-type: decimal">
<li>Spatial Statistics</li>
</ol></li>
</ul></li>
<li>The following categories be considered, at least initially, to be
out-of-scope:
<ul>
<li><ol style="list-style-type: decimal">
<li>Educational Software</li>
</ol></li>
<li><ol start="2" style="list-style-type: decimal">
<li>Visualisation Software</li>
</ol></li>
</ul></li>
</ol>
<p>Beyond these general <em>Proposals</em>, the following lists <em>Proposals</em> specific to
particular categories of statistical software:</p>
<ol style="list-style-type: decimal">
<li>For packages which parameterise or fit probability distributions, develop
routines to assess and quantify the sensitivity of outputs to the
distributional properties of inputs, and particularly to deviations from
assumed distributional properties.</li>
<li>We identify a sub-category of software which accepts <em>network inputs</em>, and
develop (or adapt) general techniques to generate generic graphs to be used
in benchmarking routines. Other software which falls within the category of
<em>Network Software</em> only because of restricted aspects such as internal data
representations (such as <code>tcherry</code>) <em>not</em> be considered or assessed within
that category.</li>
</ol>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-estivill-castro_why_2002">
<p>Estivill-Castro, Vladimir. 2002. “Why so Many Clustering Algorithms: A Position Paper.” <em>ACM SIGKDD Explorations Newsletter</em> 4 (1): 65–75. <a href="https://doi.org/10.1145/568574.568575">https://doi.org/10.1145/568574.568575</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="reading.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="standards.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": true,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ropenscilabs/statistical-software-review-book/edit/master/scope.Rmd",
"text": "Edit this chapter"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "fixed"
},
"search": false,
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
